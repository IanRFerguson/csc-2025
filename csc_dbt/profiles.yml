csc_dbt:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: service-account
      project: tmc-changemakers-2025
      dataset: csc_dbt
      threads: 1
      timeout_seconds: 1200
      location: US
      priority: interactive
      keyfile: ../service_accounts/tmc-changemakers-2025-a5d74b23cad8.json

      # NOTE - Everything below this line is ONLY required for dbt-python models
      # See the docs here - https://docs.getdbt.com/docs/core/connect-data-platform/bigquery-setup#running-python-models-on-dataproc
      gcs_bucket: csc-scratch
      dataproc_region: us-central1
      submission_method: serverless
      dataproc_batch:
        environment_config:
          execution_config:
            service_account: csc-dev@tmc-changemakers-2025.iam.gserviceaccount.com
        runtime_config:
          properties:
            spark.executor.instances: "2"
            spark.driver.cores: "4"
            spark.driver.memory: "4g"
            spark.executor.cores: "4"
            spark.executor.memory: "3g"
            spark.network.timeout: "300s"
            spark.rpc.askTimeout: "180s"
            spark.rpc.lookupTimeout: "60s"
            spark.sql.execution.arrow.maxRecordsPerBatch: "10000"
            spark.sql.adaptive.enabled: "true"
            spark.sql.adaptive.coalescePartitions.enabled: "true"

elementary:
  target: edr
  outputs:
    edr:
      type: "bigquery"
      project: "tmc-changemakers-2025"
      dataset: "csc_dbt_elementary"
      method: service-account
      # NOTE - This needs to be the ABSOLUTE path to the Service Account file
      keyfile: "{{ env_var('GOOGLE_APPLICATION_CREDENTIALS') }}"
      threads: 4  